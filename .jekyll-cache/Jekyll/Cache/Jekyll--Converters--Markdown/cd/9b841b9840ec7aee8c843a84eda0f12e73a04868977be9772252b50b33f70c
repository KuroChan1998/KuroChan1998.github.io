I"W<h1 id="redis">Redis</h1>

<p>Redis本质上是一个Key-Value类型的内存数据库，很像memcached，整个数据库统统<strong>加载在内存当中</strong>进行操作，<strong>定期通过异步操作</strong>把数据库数据flush到硬盘上进行保存。因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。</p>

<p>Redis的出色之处不仅仅是性能，Redis最大的魅力是支持保存多种数据结构，此外<strong>单个value的最大限制是1GB</strong>，不像 memcached只能保存1MB的数据，因此Redis可以用来实现很多有用的功能，比方说用他的List来做FIFO双向链表，实现一个轻量级的高性 能消息队列服务，用他的Set可以做高性能的tag系统等等。</p>

<p>另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一 个功能加强版的memcached来用。 Redis的主要缺点是<strong>数据库容量受到物理内存的限制</strong>，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在<strong>较小数据量的高性能操作和运算</strong>上。</p>

<h2 id="redis支持的数据类型">Redis支持的数据类型？</h2>

<h3 id="string字符串">String字符串</h3>

<p>格式: set key value</p>

<p>string类型是二进制安全的。意思是redis的string可以包含任何数据。比如<strong>jpg图片或者序列化的对象</strong> 。</p>

<p>string类型是Redis最基本的数据类型，一个键最大能存储512MB。</p>

<h3 id="hash哈希">Hash（哈希）</h3>

<p>格式: hmset name  key1 value1 key2 value2</p>

<p>Redis hash 是一个键值(key=&gt;value)对集合。</p>

<p>Redis hash是一个string类型的field和value的映射表，hash特别适合用于<strong>存储对象</strong>。</p>

<h3 id="list列表">List（列表）</h3>

<p>Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）</p>

<p>格式: lpush  name  value</p>

<p>在 key 对应 list 的头部添加字符串元素</p>

<p>格式: rpush  name  value</p>

<p>在 key 对应 list 的尾部添加字符串元素</p>

<p>格式: lrem name  index</p>

<p>key 对应 list 中删除 count 个和 value 相同的元素</p>

<p>格式: llen name</p>

<p>返回 key 对应 list 的长度</p>

<h3 id="set集合">Set（集合）</h3>

<p>格式: sadd  name  value</p>

<p>Redis的Set是string类型的无序集合。</p>

<p>集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。</p>

<h3 id="zsetsorted-set有序集合">zset(sorted set：有序集合)</h3>

<p>格式: zadd  name score value</p>

<p>Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。</p>

<p>不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。</p>

<p>zset的成员是唯一的,但分数(score)却可以重复。</p>

<h2 id="一个redis实例最多能存放多少的keyslistsetsorted-set他们最多能存放多少元素">一个Redis实例最多能存放多少的keys？List、Set、Sorted Set他们最多能存放多少元素？</h2>

<p>理论上Redis可以处理多达2^32的keys，并且在实际中进行了测试，每个实例至少存放了2亿5千万的keys。我们正在测试一些较大的值。</p>

<p>任何list、set、和sorted set都可以放2^32个元素。</p>

<p>换句话说，Redis的存储极限是系统中的可用内存值。</p>

<h2 id="redis有哪几种数据淘汰策略">Redis有哪几种数据淘汰策略？</h2>

<ul>
  <li>noeviction:返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）</li>
  <li>allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。</li>
  <li>volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放</li>
  <li>allkeys-random: 回收随机的键使得新添加的数据有空间存放。</li>
  <li>volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。</li>
  <li>volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。</li>
</ul>

<h2 id="redis回收进程如何工作的">Redis回收进程如何工作的？</h2>

<p>一个客户端运行了新的命令，添加了新的数据。</p>

<p>Redi检查内存使用情况，如果大于maxmemory的限制, 则根据设定好的策略进行回收。</p>

<p>一个新的命令被执行，等等。</p>

<p>所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下。</p>

<p>如果一个命令的结果导致大量内存被使用（例如很大的集合的交集保存到一个新的键），不用多久内存限制就会被这个内存使用量超越。</p>

<h2 id="redis提供了哪几种持久化方式">Redis提供了哪几种持久化方式？</h2>

<p><strong>RDB</strong>持久化方式能够在指定的时间间隔能对你的数据进行快照存储.</p>

<p><strong>AOF</strong>持久化方式<strong>记录每次对服务器写的操作</strong>,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾.Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大.</p>

<p>如果你只希望你的数据在服务器运行的时候存在,你也可以不使用任何持久化方式.</p>

<p>你也可以同时开启两种持久化方式, 在这种情况下, 当redis重启的时候会优先载入AOF文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整.</p>

<h2 id="redis-有哪些架构模式讲讲各自的特点">Redis 有哪些架构模式？讲讲各自的特点</h2>

<h3 id="单机版">单机版</h3>

<p><img src="https://github.com/KuroChan1998/KuroChan1998.github.io/blob/master/img/mdimg/1481291-20180925142100480-1152515615.png?raw=true" alt="img" /></p>

<p>特点：简单</p>

<p>问题：</p>

<p>1、内存容量有限 2、处理能力有限 3、无法高可用。</p>

<h3 id="主从复制">主从复制</h3>

<p><img src="https://github.com/KuroChan1998/KuroChan1998.github.io/blob/master/img/mdimg/1481291-20180925142118041-1727225479.png?raw=true" alt="img" /></p>

<p>Redis 的复制（replication）功能允许用户根据一个 Redis 服务器来创建任意多个该服务器的复制品，其中被复制的服务器为主服务器（master），而通过复制创建出来的服务器复制品则为从服务器（slave）。 只要主从服务器之间的网络连接正常，主从服务器两者会具有相同的数据，主服务器就会一直将发生在自己身上的数据更新同步 给从服务器，从而一直保证主从服务器的数据相同。</p>

<p>特点：</p>

<p>1、master/slave 角色</p>

<p>2、master/slave 数据相同</p>

<p>3、降低 master 读压力在转交从库</p>

<p>问题：</p>

<p>无法保证高可用</p>

<p>没有解决 master 写的压力</p>

<h3 id="哨兵">哨兵</h3>

<p><strong><img src="https://github.com/KuroChan1998/KuroChan1998.github.io/blob/master/img/mdimg/1481291-20180925142143478-1454265814.png?raw=true" alt="img" /></strong></p>

<p>Redis sentinel 是一个分布式系统中监控 redis 主从服务器，并在主服务器下线时自动进行故障转移。其中三个特性：</p>

<p>监控（Monitoring）：    Sentinel  会不断地检查你的主服务器和从服务器是否运作正常。</p>

<p>提醒（Notification）： 当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。</p>

<p>自动故障迁移（Automatic failover）： 当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作。</p>

<p>特点：</p>

<p>1、保证高可用</p>

<p>2、监控各个节点</p>

<p>3、自动故障迁移</p>

<p>缺点：主从模式，切换需要时间丢数据</p>

<p>没有解决 master 写的压力</p>

<h3 id="集群proxy-型">集群（proxy 型）：</h3>

<p><strong><img src="https://github.com/KuroChan1998/KuroChan1998.github.io/blob/master/img/mdimg/1481291-20180925142206124-913246424.png?raw=true" alt="img" /></strong></p>

<p>Twemproxy 是一个 Twitter 开源的一个 redis 和 memcache 快速/轻量级代理服务器； Twemproxy 是一个快速的单线程代理程序，支持 Memcached ASCII 协议和 redis 协议。</p>

<p>特点：1、多种 hash 算法：MD5、CRC16、CRC32、CRC32a、hsieh、murmur、Jenkins</p>

<p>2、支持失败节点自动删除</p>

<p>3、后端 Sharding 分片逻辑对业务透明，业务方的读写方式和操作单个 Redis 一致</p>

<p>缺点：增加了新的 proxy，需要维护其高可用。</p>

<p>failover 逻辑需要自己实现，其本身不能支持故障的自动转移可扩展性差，进行扩缩容都需要手动干预</p>

<h3 id="集群直连型">集群（直连型）：</h3>

<p><strong><img src="https://github.com/KuroChan1998/KuroChan1998.github.io/blob/master/img/mdimg/1481291-20180925142304757-1498788186.png?raw=true" alt="img" /></strong></p>

<p>从redis 3.0之后版本支持redis-cluster集群，Redis-Cluster采用无中心结构，每个节点保存数据和整个集群状态,每个节点都和其他所有节点连接。</p>

<p>特点：</p>

<p>1、无中心架构（不存在哪个节点影响性能瓶颈），少了 proxy 层。</p>

<p>2、数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调整数据分布。</p>

<p>3、可扩展性，可线性扩展到 1000 个节点，节点可动态添加或删除。</p>

<p>4、高可用性，部分节点不可用时，集群仍可用。通过增加 Slave 做备份数据副本</p>

<p>5、实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投票机制完成 Slave到 Master 的角色提升。</p>

<p>缺点：</p>

<p>1、资源隔离性较差，容易出现相互影响的情况。</p>

<p>2、数据通过异步复制,不保证数据的强一致性</p>

<h2 id="redis集群方案应该怎么做都有哪些方案">Redis集群方案应该怎么做？都有哪些方案？</h2>

<ol>
  <li>twemproxy，大概概念是，它类似于一个代理方式，使用方法和普通redis无任何区别，设置好它下属的多个redis实例后，使用时在本需要连接redis的地方改为连接twemproxy，<strong>它会以一个代理的身份接收请求并使用一致性hash算法，将请求转接到具体redis，将结果再返回twemproxy</strong>。使用方式简便(相对redis只需修改连接端口)，对旧项目扩展的首选。 问题：twemproxy自身单端口实例的压力，使用一致性hash后，对redis节点数量改变时候的计算值的改变，数据无法自动移动到新的节点。</li>
  <li>codis，目前用的最多的集群方案，基本和twemproxy一致的效果，但它支持在 节点数量改变情况下，旧节点数据可恢复到新hash节点。</li>
  <li>redis cluster3.0自带的集群，特点在于他的分布式算法不是一致性hash，而是hash槽的概念，以及自身支持节点设置从节点。具体看官方文档介绍。</li>
</ol>

<h2 id="redis集群-数据迁移方式-hash槽-和-一致性hash对比优缺点比较">redis集群 数据迁移方式 Hash槽 和 一致性hash对比，优缺点比较</h2>

<h3 id="简单哈希算法">简单哈希算法</h3>

<p>假设有三台机，数据落在哪台机的算法为：</p>

<p>c = Hash(key) % 3</p>

<p>例如 key A 的哈希值为4，4 % 3 = 1，则落在第二台机。Key ABC 哈希值为11，11 % 3 = 2，则落在第三台机上。</p>

<p>利用这样的算法，假设现在数据量太大了，需要增加一台机器。A 原本落在第二台上，现在根据算法4 % 4 = 0，落到了第一台机器上了，但是第一台机器上根本没有 A 的值。这样的算法<strong>会导致增加机器或减少机器的时候，引起大量的缓存穿透，造成雪崩</strong>。</p>

<h3 id="一致性哈希算法">一致性哈希算法</h3>

<p>在一致性哈希算法中，整个哈希空间是一个虚拟圆环。</p>

<p>假设有四个节点 Node A、B、C、D，经过 ip 地址的哈希计算，它们的位置如下：</p>

<p>有4个存储对象 Object A、B、C、D，经过对 Key 的哈希计算后，它们的位置如下：</p>

<table>
  <tbody>
    <tr>
      <td>![img](https://github.com/KuroChan1998/KuroChan1998.github.io/blob/master/img/mdimg/4337694-52e11e3547d9b5a5.png?imageMogr2/auto-orient/strip</td>
      <td>imageView2/2/w/704/format/webp)</td>
    </tr>
  </tbody>
</table>

<p>对于各个 Object，它所真正的存储位置是<strong>按顺时针找到的第一个存储节点</strong>。例如 Object A 顺时针找到的第一个节点是 Node A，所以 Node A 负责存储 Object A，Object B 存储在 Node B。</p>

<p>一致性哈希算法大概如此，那么它的容错性和扩展性如何呢？</p>

<p>假设 Node C 节点挂掉了，Object C 的存储丢失，那么它顺时针找到的最新节点是 Node D。也就是说 Node C 挂掉了，<strong>受影响仅仅包括 Node B 到 Node C 区间的数据，并且这些数据会转移到 Node D 进行存储</strong>。</p>

<p><img src="https://github.com/KuroChan1998/KuroChan1998.github.io/blob/master/img/mdimg/4337694-db75beb80816f60f.png?raw=true" alt="img" /></p>

<p>同理，假设现在数据量大了，需要增加一台节点 Node X。Node X 的位置在 Node B 到 Node C 直接，那么受到影响的仅仅是 Node B 到 Node X 间的数据，它们要重新落到 Node X 上。</p>

<p>所以一致性哈希算法对于容错性和扩展性有非常好的支持。但一致性哈希算法也有一个严重的问题，就是<strong>数据倾斜</strong>。</p>

<p>如果在分片的集群中，节点太少，并且分布不均，一致性哈希算法就会出现部分节点数据太多，部分节点数据太少。也就是说无法控制节点存储数据的分配。如下图，大部分数据都在 A 上了，B 的数据比较少。</p>

<p><img src="https://github.com/KuroChan1998/KuroChan1998.github.io/blob/master/img/mdimg/4337694-c5a3c24d519bc9f2.png?raw=true" alt="img" /></p>

<h3 id="哈希槽">哈希槽</h3>

<p>分片:
Redis Cluster在设计中没有使用一致性哈希（Consistency Hashing），而是使用数据分片引入哈希槽（hash slot）来实现；</p>

<p>一个 Redis Cluster包含16384（0~16383）个哈希槽，存储在Redis Cluster中的所有键都会被映射到这些slot中，</p>

<p>集群中的每个键都属于这16384个哈希槽中的一个，<strong>集群使用公式slot=CRC16（key）/16384来计算key属于哪个槽</strong>，其中CRC16(key)语句用于计算key的CRC16 校验和。</p>

<p>按照槽来进行分片，通过<strong>为每个节点指派不同数量的槽</strong>，可以控制不同节点负责的数据量和请求数.</p>

<p><img src="https://github.com/KuroChan1998/KuroChan1998.github.io/blob/master/img/mdimg/20180103174652115.jpg?raw=true" alt="img" /></p>

<p>当前集群有3个节点,槽默认是平均分的:
节点 A （6381）包含 0 到 5499号哈希槽.
节点 B （6382）包含5500 到 10999 号哈希槽.
节点 C （6383）包含11000 到 16383号哈希槽.
<strong>这种结构很容易添加或者删除节点</strong>. 比如如果我想新添加个节点D, 我需要从节点 A, B, C中得部分槽到D上. 如果我像移除节点A,需要将A中得槽移到B和C节点上,然后将没有任何槽的A节点从集群中移除即可. 由于从一个节点将哈希槽移动到另一个节点并不会停止服务,所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态.</p>

<ul>
  <li>
    <p>数据迁移
数据迁移可以理解为slot(槽)和key的迁移，这个功能很重要，极大地方便了集群做线性扩展，以及实现平滑的扩容或缩容。</p>

    <p>现在要将Master A节点中编号为1、2、3的slot迁移到Master B节点中，在slot迁移的中间状态下，slot 1、2、3在Master A节点的状态表现为MIGRATING（迁移）,在Master B节点的状态表现为IMPORTING（入口）。</p>
  </li>
</ul>

<p><img src="https://github.com/KuroChan1998/KuroChan1998.github.io/blob/master/img/mdimg/20180103174740149.jpg?raw=true" alt="img" /></p>

<p><img src="https://img-blog.csdn.net/20180103174824673" alt="img" /></p>

<p>复制&amp;高可用:
集群的节点内置了复制和高可用特性。</p>

<p>特点：1、节点自动发现
2、slave-&gt;master 选举,集群容错
3、Hot resharding:在线分片
4、基于配置(nodes-port.conf)的集群管理
5、客户端与redis节点直连、不需要中间proxy层.
6、所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽.</p>

<h2 id="如何保持mysql和redis的一致性">如何保持MySQL和Redis的一致性？</h2>

<p>​      如题，现在很多架构都采用了Redis+MySQL来进行存储，但是由于多方面的原因，总会导致Redis和MySQL之间出现数据的不一致性。</p>

<p>​      例如如果一个事务执行失败回滚了，但是如果采取了先写Redis的方式，就会造成Redis和MySQL数据库的不一致，再比如说，一个事务写入了MySQL，但是此时还未写入Redis，如果这时候有用户访问Redis，则此时就会出现数据不一致。</p>

<p>​      为了解决这些问题，本文将着重讨论，如何保证MySQL和Redis之间存在一个合理的数据一致性方案。</p>

<h3 id="1分别处理">1、分别处理</h3>

<p>​      针对某些对数据一致性要求不是特别高的情况下，可以<strong>将这些数据放入Redis，请求来了直接查询Redis</strong>，例如近期回复、历史排名这种<strong>实时性不强</strong>的业务。而针对那些<strong>强实时性的业务</strong>，例如虚拟货币、物品购买件数等等，则直接穿透Redis至MySQL上，<strong>等到MySQL上写入成功，再同步更新到Redis上去</strong>。这样既可以起到Redis的分流大量查询请求的作用，又保证了关键数据的一致性。</p>

<h3 id="2高并发情况下">2、高并发情况下</h3>

<p>​       此时如果写入请求较多，则直接写入Redis中去，然后<strong>间隔一段时间，批量将所有的写入请求</strong>，刷新到MySQL中去；如果此时写入请求不多，则可以在每次写入Redis，都立刻将该命令同步至MySQL中去。这两种方法有利有弊，需要根据不同的场景来权衡。</p>

<h3 id="3基于订阅binlog的同步机制">3、基于订阅binlog的同步机制</h3>

<p>​       阿里巴巴的一款开源框架canal，提供了一种发布/ 订阅模式的同步机制，通过该框架我们<strong>可以对MySQL的binlog进行订阅，这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新</strong>。值得注意的是，binlog需要手动打开，并且不会记录关于MySQL查询的命令和操作。</p>

<p>​       其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。而canal正是模仿了slave数据库的备份请求，使得Redis的数据更新达到了相同的效果。如下图就可以看到Slave数据库中启动了2个线程，一个是MySQL SQL线程，这个线程跟Matser数据库中起的线程是一样的，负责MySQL的业务率执行，而另外一个线程就是MySQL的I/O线程，这个线程的主要作用就是同步Master 数据库中的binlog，达到数据备份的效果。而binlog就可以理解为一堆SQL语言组成的日志。</p>

<p><img src="https://github.com/KuroChan1998/KuroChan1998.github.io/blob/master/img/mdimg/20180601215704890.png?raw=true" alt="img" /></p>

<h2 id="使用过redis做异步队列么你是怎么用的有什么缺点">使用过Redis做异步队列么，你是怎么用的？有什么缺点？</h2>

<p>一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。</p>

<p>缺点：在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。</p>

<h2 id="什么是缓存穿透如何避免什么是缓存雪崩何如避免">什么是缓存穿透？如何避免？什么是缓存雪崩？何如避免？</h2>

<h3 id="缓存穿透">缓存穿透</h3>

<p>一般的缓存系统，都是按照key去缓存查询，如果不存在对应的value，就应该去后端系统查找（比如DB）。一些恶意的请求会故意查询不存在的key,请求量很大，就会对后端系统造成很大的压力。这就叫做缓存穿透。</p>

<p>如何避免？</p>

<p>1：<strong>对查询结果为空的情况也进行缓存</strong>，缓存时间设置短一点，或者该key对应的数据insert了之后清理缓存。</p>

<p>2：对一定不存在的key进行过滤。可以把所有的可能存在的key放到一个大的Bitmap中，查询时通过该bitmap过滤。</p>

<h3 id="缓存雪崩">缓存雪崩</h3>

<p>当缓存服务器重启或者<strong>大量缓存集中在某一个时间段失效</strong>，这样在失效的时候，会给后端系统带来很大压力。导致系统崩溃。</p>

<p>如何避免？</p>

<p>1：在缓存失效后，通过<strong>加锁或者队列</strong>来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。</p>

<p>2：做二级缓存，A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期</p>

<p>3：不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。</p>
:ET